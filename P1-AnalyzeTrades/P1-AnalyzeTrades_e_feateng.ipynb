{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d9e183",
   "metadata": {},
   "source": [
    "# E: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334c4ff",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "95c96570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.412412Z",
     "start_time": "2022-07-17T20:54:34.401409Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for na pipeline\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import TransformerMixin  # for custom transformers\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33d684",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d6ccabda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.506411Z",
     "start_time": "2022-07-17T20:54:34.417413Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "df_XY = pd.read_csv(\"output/c_resulttradewattr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b447cd2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.538415Z",
     "start_time": "2022-07-17T20:54:34.512413Z"
    }
   },
   "outputs": [],
   "source": [
    "##  get_feature_names function\n",
    "# https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    # check_is_fitted(column_transformer)\n",
    "\n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == \"drop\" or (hasattr(column, \"__len__\") and not len(column)):\n",
    "            return []\n",
    "        if trans == \"passthrough\":\n",
    "            if hasattr(column_transformer, \"_df_columns\"):\n",
    "                if (not isinstance(column, slice)) and all(\n",
    "                    isinstance(col, str) for col in column\n",
    "                ):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return [i for i in indices[column]]\n",
    "        if not hasattr(trans, \"get_feature_names\"):\n",
    "            # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\n",
    "                \"Transformer %s (type %s) does not \"\n",
    "                \"provide get_feature_names. \"\n",
    "                \"Will return input column names if available\"\n",
    "                % (str(name), type(trans).__name__)\n",
    "            )\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names()]\n",
    "\n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "\n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == sklearn.pipeline.Pipeline:\n",
    "        l_transformers = [\n",
    "            (name, trans, None) for step, name, trans in column_transformer._iter()\n",
    "        ]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = column_transformer.transformers_\n",
    "\n",
    "    for name, trans, column in l_transformers:\n",
    "        if type(trans) == sklearn.pipeline.Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names) == 0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a0007",
   "metadata": {},
   "source": [
    "## custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3331ab60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.572408Z",
     "start_time": "2022-07-17T20:54:34.543411Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Numerizer(TransformerMixin):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "#         Y = X.apply(pd.to_numeric, args=({\"errors\":\"coerce\"})).fillna(np.nan)\n",
    "\n",
    "        Y = X.apply((lambda x: (\n",
    "            pd.to_numeric(x.astype(str).str.replace(r'%', r'e-2'),errors='coerce')\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return Y\n",
    "\n",
    "\n",
    "class StringTransformer(TransformerMixin):\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Y = pd.DataFrame(X).astype(\"string\")\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df66cb",
   "metadata": {},
   "source": [
    "## Add Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0c1ba452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.584411Z",
     "start_time": "2022-07-17T20:54:34.577408Z"
    }
   },
   "outputs": [],
   "source": [
    "df_XY['Age'] = df_XY['Open_Year'] - min(df_XY['Open_Year']-1)\n",
    "df_XY['Weight'] = df_XY['Age'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbf2ee",
   "metadata": {},
   "source": [
    "## create na pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "351d6bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.616410Z",
     "start_time": "2022-07-17T20:54:34.590410Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 0, dtype: object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY.loc[0,df_XY.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce3267dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.662409Z",
     "start_time": "2022-07-17T20:54:34.621411Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove all nan columns\n",
    "df_XY = df_XY.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "da5d1dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.694407Z",
     "start_time": "2022-07-17T20:54:34.665409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'Open_Date', 'Close_Date',\n",
       "       'Symbol', 'Quantity', 'Pnl', 'OpenAct', 'CloseAct', 'Open_Price',\n",
       "       'Close_Price', 'Comm_Tot', 'DATE', 'ACTION', 'QTYCHG', 'PRICE', 'TIME',\n",
       "       'UNNAMED: 6', 'COMMISSION', 'UNNAMED: 8', 'CASH CHG (PNL)', 'COMMENTS',\n",
       "       'PCTRETURN', 'STARTDATE', 'COMPANY NAME (IN ALPHABETICAL ORDER)',\n",
       "       'TICKER', 'STOP', '% TO STOP', 'CURRENT PRICE', '% TO TARGET',\n",
       "       'AT PRICE', 'TARGET', 'EPS1', 'EPS2', 'FYEND', 'DAYSTOFYEND',\n",
       "       'FYEPSNXT', 'GROWTH*0.5TO0.75', 'ROIC (BW ROA ROE)', 'TGT FWD P/E',\n",
       "       'YEARS TO NORMALIZATION', 'LASTUPDATED', 'CATEGORY', 'COMMENTS.1',\n",
       "       'FILENAME', 'DayOfWeek0Mon', 'Date_YahooFinance', 'Close_^GSPC',\n",
       "       'Close_^VIX', 'Open_Year', 'AAII_SENT_Date', 'AAII_SENT_Bullish',\n",
       "       'AAII_SENT_Neutral', 'AAII_SENT_Bearish', 'AAII_SENT_Total',\n",
       "       'AAII_SENT_Bullish8WeekMovAvg', 'AAII_SENT_BullBearSpread',\n",
       "       'AAII_SENT_BullishAverage', 'AAII_SENT_BullishAverage+StDev',\n",
       "       'AAII_SENT_BullishAverageStDev', 'AAII_SENT_S&P500WeeklyHigh',\n",
       "       'AAII_SENT_S&P500WeeklyLow', 'AAII_SENT_S&P500WeeklyClose', 'Date',\n",
       "       'Age', 'Weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XY.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e4728a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:34.725411Z",
     "start_time": "2022-07-17T20:54:34.699410Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAII_SENT_BULLISHAVERAGESTDEV',\n",
       " 'QTYCHG',\n",
       " 'ROIC_(BW_ROA_ROE)',\n",
       " 'PRICE',\n",
       " 'AAII_SENT_TOTAL',\n",
       " 'QUANTITY',\n",
       " 'DETAILS',\n",
       " 'CLOSE_PRICE',\n",
       " 'AAII_SENT_BULLISH',\n",
       " '%_TO_TARGET',\n",
       " 'AAII_SENT_NEUTRAL',\n",
       " 'COMM_TOT',\n",
       " 'UNNAMED:_0',\n",
       " 'CLOSE_^GSPC',\n",
       " 'OPEN_PRICE',\n",
       " 'AAII_SENT_BULLISHAVERAGE',\n",
       " 'UNNAMED:_0.2',\n",
       " 'AAII_SENT_BEARISH',\n",
       " 'AAII_SENT_BULLBEARSPREAD',\n",
       " 'YEARS_TO_NORMALIZATION',\n",
       " 'UNNAMED:_0.1',\n",
       " 'AAII_SENT_S&P500WEEKLYCLOSE',\n",
       " 'TGT_FWD_P_E',\n",
       " 'PNL',\n",
       " 'AGE',\n",
       " 'GROWTH_0.5TO0.75',\n",
       " 'AAII_SENT_BULLISHAVERAGE+STDEV',\n",
       " 'DAYOFWEEK0MON',\n",
       " 'AAII_SENT_S&P500WEEKLYLOW',\n",
       " 'CLOSE_^VIX',\n",
       " 'AAII_SENT_BULLISH8WEEKMOVAVG',\n",
       " '%_TO_STOP',\n",
       " 'OPEN_YEAR',\n",
       " 'WEIGHT',\n",
       " 'AAII_SENT_S&P500WEEKLYHIGH',\n",
       " 'COMMISSION',\n",
       " 'CASH_CHG_(PNL)',\n",
       " 'PCTRETURN',\n",
       " 'DATE',\n",
       " 'DATE_YAHOOFINANCE',\n",
       " 'TICKER',\n",
       " 'CLOSEACT',\n",
       " 'CATEGORY',\n",
       " 'COMMENTS',\n",
       " 'UNNAMED:_8',\n",
       " 'FYEPSNXT',\n",
       " 'EPS1',\n",
       " 'COMPANY_NAME_(IN_ALPHABETICAL_ORDER)',\n",
       " 'TIME',\n",
       " 'UNNAMED:_6',\n",
       " 'DAYSTOFYEND',\n",
       " 'OPENACT',\n",
       " 'ACTION',\n",
       " 'CLOSE_DATE',\n",
       " 'OPEN_DATE',\n",
       " 'CURRENT_PRICE',\n",
       " 'LASTUPDATED',\n",
       " 'AAII_SENT_DATE',\n",
       " 'STOP',\n",
       " 'TARGET',\n",
       " 'STARTDATE',\n",
       " 'AT_PRICE',\n",
       " 'COMMENTS.1',\n",
       " 'FYEND',\n",
       " 'FILENAME',\n",
       " 'SYMBOL',\n",
       " 'EPS2']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "54add40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.194406Z",
     "start_time": "2022-07-17T20:54:34.736414Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_28756\\1557959305.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  pd.Series(df_XY.columns)\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_28756\\3465394604.py:32: UserWarning: Transformer numerizer (type Numerizer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_28756\\3465394604.py:32: UserWarning: Transformer imputer (type SimpleImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_28756\\3465394604.py:32: UserWarning: Transformer stringtransformer (type StringTransformer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# update columns headers to clean up\n",
    "df_XY.columns = list(\n",
    "    pd.Series(df_XY.columns)\n",
    "    .astype(str)\n",
    "    .str.replace(\" \", \"_\", regex=True)\n",
    "    .str.upper()\n",
    "    .str.strip()\n",
    "    .str.replace(\"/\", \"_\")\n",
    "    .str.replace(\"*\", \"_\")\n",
    ")\n",
    "\n",
    "# avoid duplicates\n",
    "df_XY = df_XY.loc[:,~df_XY.columns.duplicated()]\n",
    "\n",
    "# start with numeric, utilizng explore data before\n",
    "numeric_features = df_XY.convert_dtypes().select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_features = numeric_features + [\n",
    "    \"%_TO_STOP\",\n",
    "    \"%_TO_TARGET\",\n",
    "    \"GROWTH_0.5TO0.75\",\n",
    "    \"ROIC_(BW_ROA_ROE)\",\n",
    "    \"TGT_FWD_P_E\",\n",
    "    \"YEARS_TO_NORMALIZATION\",\n",
    "]\n",
    "numeric_features = list(set(numeric_features))\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"numerizer\", Numerizer()),\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan,strategy=\"median\")),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"_NA_\")),\n",
    "        (\"stringtransformer\", StringTransformer()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# numerical\n",
    "\n",
    "# categorical_features = ['embarked', 'sex', 'pclass']\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_features = list(set(df_XY.columns).difference(set(numeric_features)))\n",
    "\n",
    "preprocessor_na = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    # remainder = 'passthrough' # not needed anymore\n",
    ")\n",
    "\n",
    "XY_imputed = preprocessor_na.fit_transform(df_XY)\n",
    "\n",
    "columns = get_feature_names(preprocessor_na)\n",
    "\n",
    "df_XY_imputed = pd.DataFrame(XY_imputed, columns=columns).convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f3cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bfa62f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.209410Z",
     "start_time": "2022-07-17T20:54:35.197408Z"
    }
   },
   "outputs": [],
   "source": [
    "# create target\n",
    "\n",
    "df_XY_imputed[\"PCT_RET_FINAL\"] = df_XY_imputed[\"PNL\"] / (\n",
    "    df_XY_imputed[\"OPEN_PRICE\"] * df_XY_imputed[\"QUANTITY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6f75aa8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.225406Z",
     "start_time": "2022-07-17T20:54:35.215419Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TODO create moving avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8179bfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.240410Z",
     "start_time": "2022-07-17T20:54:35.230410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AAII_SENT_BULLISHAVERAGESTDEV', 'QTYCHG', 'ROIC_(BW_ROA_ROE)', 'PRICE',\n",
      "       'AAII_SENT_TOTAL', 'QUANTITY', 'CLOSE_PRICE', 'AAII_SENT_BULLISH',\n",
      "       '%_TO_TARGET', 'AAII_SENT_NEUTRAL', 'COMM_TOT', 'UNNAMED:_0',\n",
      "       'CLOSE_^GSPC', 'OPEN_PRICE', 'AAII_SENT_BULLISHAVERAGE', 'UNNAMED:_0.2',\n",
      "       'AAII_SENT_BEARISH', 'AAII_SENT_BULLBEARSPREAD',\n",
      "       'YEARS_TO_NORMALIZATION', 'UNNAMED:_0.1', 'AAII_SENT_S&P500WEEKLYCLOSE',\n",
      "       'TGT_FWD_P_E', 'PNL', 'AGE', 'GROWTH_0.5TO0.75',\n",
      "       'AAII_SENT_BULLISHAVERAGE+STDEV', 'DAYOFWEEK0MON',\n",
      "       'AAII_SENT_S&P500WEEKLYLOW', 'CLOSE_^VIX',\n",
      "       'AAII_SENT_BULLISH8WEEKMOVAVG', '%_TO_STOP', 'OPEN_YEAR', 'WEIGHT',\n",
      "       'AAII_SENT_S&P500WEEKLYHIGH', 'COMMISSION', 'CASH_CHG_(PNL)',\n",
      "       'PCTRETURN', 'DATE', 'DATE_YAHOOFINANCE', 'TICKER', 'CLOSEACT',\n",
      "       'CATEGORY', 'COMMENTS', 'UNNAMED:_8', 'FYEPSNXT', 'EPS1',\n",
      "       'COMPANY_NAME_(IN_ALPHABETICAL_ORDER)', 'TIME', 'UNNAMED:_6',\n",
      "       'DAYSTOFYEND', 'OPENACT', 'ACTION', 'CLOSE_DATE', 'OPEN_DATE',\n",
      "       'CURRENT_PRICE', 'LASTUPDATED', 'AAII_SENT_DATE', 'STOP', 'TARGET',\n",
      "       'STARTDATE', 'AT_PRICE', 'COMMENTS.1', 'FYEND', 'FILENAME', 'SYMBOL',\n",
      "       'EPS2', 'PCT_RET_FINAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Final columns\n",
    "\n",
    "print(df_XY_imputed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "925b9084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.271410Z",
     "start_time": "2022-07-17T20:54:35.244410Z"
    }
   },
   "outputs": [],
   "source": [
    "## check no na's left in numerical\n",
    "\n",
    "try:\n",
    "    assert (\n",
    "        df_XY_imputed[numeric_features].isna().sum().sum() == 0\n",
    "    ), \"NAs remain in numerical\"\n",
    "except:\n",
    "    print(\"NAs remain in numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad761e04",
   "metadata": {},
   "source": [
    "## API Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d620b42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:35.350410Z",
     "start_time": "2022-07-17T20:54:35.275412Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## import api spec\n",
    "\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "\n",
    "with open(\"data-tests/_apispecs.yaml\") as f:\n",
    "    api_specs = yaml.load(f, Loader=Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d6570cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:41.128779Z",
     "start_time": "2022-07-17T20:54:35.354410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation completed\n"
     ]
    }
   ],
   "source": [
    "## validate based on api spec\n",
    "\n",
    "from openapi_schema_validator import validate\n",
    "import json\n",
    "\n",
    "schema = api_specs[\"components\"][\"schemas\"][\"Tradelog\"]\n",
    "\n",
    "json_str = df_XY_imputed.to_json(orient=\"records\")\n",
    "json_test = json.loads(json_str)\n",
    "\n",
    "i = 0\n",
    "for row in json_test:\n",
    "    try:\n",
    "        validate(row, schema)\n",
    "    except:\n",
    "        print(f\"failed on {i}th row \")\n",
    "        break\n",
    "    i = i + 1\n",
    "\n",
    "print(\"validation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "72f92a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:41.445305Z",
     "start_time": "2022-07-17T20:54:41.130779Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save api spec to html\n",
    "\n",
    "import os\n",
    "\n",
    "# feed yaml file to swagger python, then create api.html\n",
    "os.system(\n",
    "    \"python swagger_yaml_to_html.py < data-tests/_apispecs.yaml > templates/api.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6574f30",
   "metadata": {},
   "source": [
    "## Resort & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d722f77c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:41.461307Z",
     "start_time": "2022-07-17T20:54:41.448304Z"
    }
   },
   "outputs": [],
   "source": [
    "df_XY_imputed = df_XY_imputed.reindex(sorted(df_XY_imputed.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b01a7cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:41.699301Z",
     "start_time": "2022-07-17T20:54:41.466305Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## save results\n",
    "\n",
    "df_XY_imputed.to_csv(\"output/e_resultcleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c5d949fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T20:54:41.731306Z",
     "start_time": "2022-07-17T20:54:41.705305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/e_preprocessor_na.joblib']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save imputer\n",
    "\n",
    "dump(preprocessor_na, \"output/e_preprocessor_na.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:percent,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "p1analyzetrades",
   "language": "python",
   "name": "p1analyzetrades"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
