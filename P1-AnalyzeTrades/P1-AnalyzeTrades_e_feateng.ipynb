{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d9e183",
   "metadata": {},
   "source": [
    "# E: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334c4ff",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c96570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:03.838610Z",
     "start_time": "2022-07-05T14:21:01.779539Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for na pipeline\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import TransformerMixin  # for custom transformers\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33d684",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ccabda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.026542Z",
     "start_time": "2022-07-05T14:21:03.843545Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "df_XY = pd.read_csv(\"output/c_resulttradewattr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b447cd2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.058537Z",
     "start_time": "2022-07-05T14:21:04.030538Z"
    }
   },
   "outputs": [],
   "source": [
    "##  get_feature_names function\n",
    "# https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    # check_is_fitted(column_transformer)\n",
    "\n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == \"drop\" or (hasattr(column, \"__len__\") and not len(column)):\n",
    "            return []\n",
    "        if trans == \"passthrough\":\n",
    "            if hasattr(column_transformer, \"_df_columns\"):\n",
    "                if (not isinstance(column, slice)) and all(\n",
    "                    isinstance(col, str) for col in column\n",
    "                ):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return [i for i in indices[column]]\n",
    "        if not hasattr(trans, \"get_feature_names\"):\n",
    "            # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\n",
    "                \"Transformer %s (type %s) does not \"\n",
    "                \"provide get_feature_names. \"\n",
    "                \"Will return input column names if available\"\n",
    "                % (str(name), type(trans).__name__)\n",
    "            )\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names()]\n",
    "\n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "\n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == sklearn.pipeline.Pipeline:\n",
    "        l_transformers = [\n",
    "            (name, trans, None) for step, name, trans in column_transformer._iter()\n",
    "        ]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = column_transformer.transformers_\n",
    "\n",
    "    for name, trans, column in l_transformers:\n",
    "        if type(trans) == sklearn.pipeline.Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names) == 0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3331ab60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.074536Z",
     "start_time": "2022-07-05T14:21:04.065539Z"
    }
   },
   "outputs": [],
   "source": [
    "## custom transformers\n",
    "class Numerizer(TransformerMixin):\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Y = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "        return Y\n",
    "\n",
    "\n",
    "class StringTransformer(TransformerMixin):\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Y = pd.DataFrame(X).astype(\"string\")\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbf2ee",
   "metadata": {},
   "source": [
    "## create na pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54add40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.260541Z",
     "start_time": "2022-07-05T14:21:04.079546Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_67768\\61775179.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  pd.Series(df_XY.columns)\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_67768\\3465394604.py:32: UserWarning: Transformer numerizer (type Numerizer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_67768\\3465394604.py:32: UserWarning: Transformer imputer (type SimpleImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_67768\\3465394604.py:32: UserWarning: Transformer stringtransformer (type StringTransformer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# update columns headers to clean up\n",
    "df_XY.columns = list(\n",
    "    pd.Series(df_XY.columns)\n",
    "    .astype(str)\n",
    "    .str.replace(\" \", \"_\", regex=True)\n",
    "    .str.upper()\n",
    "    .str.strip()\n",
    "    .str.replace(\"/\", \"_\")\n",
    "    .str.replace(\"*\", \"_\")\n",
    ")\n",
    "\n",
    "# start with numeric, utilizng explore data before\n",
    "numeric_features = df_XY.select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_features = numeric_features + [\n",
    "    \"%_TO_STOP\",\n",
    "    \"%_TO_TARGET\",\n",
    "    \"GROWTH_0.5TO0.75\",\n",
    "    \"ROIC_(BW_ROA_ROE)\",\n",
    "    \"TGT_FWD_P_E\",\n",
    "    \"YEARS_TO_NORMALIZATION\",\n",
    "]\n",
    "numeric_features = list(set(numeric_features))\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"numerizer\", Numerizer()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"_NA_\")),\n",
    "        (\"stringtransformer\", StringTransformer()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# numerical\n",
    "\n",
    "# categorical_features = ['embarked', 'sex', 'pclass']\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_features = list(set(df_XY.columns).difference(set(numeric_features)))\n",
    "\n",
    "preprocessor_na = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    # remainder = 'passthrough' # not needed anymore\n",
    ")\n",
    "\n",
    "XY_imputed = preprocessor_na.fit_transform(df_XY)\n",
    "\n",
    "columns = get_feature_names(preprocessor_na)\n",
    "\n",
    "df_XY_imputed = pd.DataFrame(XY_imputed, columns=columns).convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa62f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.293567Z",
     "start_time": "2022-07-05T14:21:04.265538Z"
    }
   },
   "outputs": [],
   "source": [
    "# create target\n",
    "\n",
    "df_XY_imputed[\"PCT_RET_FINAL\"] = df_XY_imputed[\"PNL\"] / (\n",
    "    df_XY_imputed[\"OPEN_PRICE\"] * df_XY_imputed[\"QUANTITY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f75aa8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.307541Z",
     "start_time": "2022-07-05T14:21:04.300539Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TODO create moving avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8179bfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.338538Z",
     "start_time": "2022-07-05T14:21:04.316540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AAII_SENT_BULLISHAVERAGE', 'OPEN_PRICE', 'QUANTITY', 'TGT_FWD_P_E',\n",
      "       'UNNAMED:_0.1', 'AAII_SENT_BULLBEARSPREAD', 'CLOSE_PRICE',\n",
      "       'AAII_SENT_BEARISH', 'PNL', 'AAII_SENT_BULLISH8WEEKMOVAVG', 'DETAILS',\n",
      "       'UNNAMED:_0', 'COMM_TOT', 'UNNAMED:_0_Y', 'AAII_SENT_S&P500WEEKLYCLOSE',\n",
      "       'YEARS_TO_NORMALIZATION', 'CLOSE_^GSPC', '%_TO_STOP',\n",
      "       'AAII_SENT_BULLISHAVERAGE+STDEV', 'GROWTH_0.5TO0.75', 'CLOSE_^VIX',\n",
      "       'AAII_SENT_NEUTRAL', 'ROIC_(BW_ROA_ROE)', 'AAII_SENT_S&P500WEEKLYHIGH',\n",
      "       '%_TO_TARGET', 'AAII_SENT_S&P500WEEKLYLOW', 'UNNAMED:_0_X',\n",
      "       'COMMISSION', 'AAII_SENT_BULLISHAVERAGESTDEV', 'PRICE',\n",
      "       'AAII_SENT_TOTAL', 'AAII_SENT_BULLISH', 'QTYCHG', 'STARTDATE',\n",
      "       'FYEPSNXT', 'FYEND', 'CLOSE_DATE', 'FILENAME', 'PCTRETURN', 'EPS2',\n",
      "       'DATE', 'TIME', 'CASH_CHG_(PNL)', 'CLOSEACT', 'TARGET', 'DATE_',\n",
      "       'LASTUPDATED', 'EPS1', 'UNNAMED:_8', 'SYMBOL', 'CATEGORY', 'AT_PRICE',\n",
      "       'OPENACT', 'TICKER', 'COMPANY_NAME_(IN_ALPHABETICAL_ORDER)',\n",
      "       'CURRENT_PRICE', 'DAYSTOFYEND', 'AAII_SENT_DATE', 'ACTION',\n",
      "       'COMMENTS.1', 'OPEN_DATE', 'COMMENTS', 'UNNAMED:_6', 'STOP',\n",
      "       'PCT_RET_FINAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Final columns\n",
    "\n",
    "print(df_XY_imputed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "925b9084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.368540Z",
     "start_time": "2022-07-05T14:21:04.349545Z"
    }
   },
   "outputs": [],
   "source": [
    "## check no na's left in numerical\n",
    "\n",
    "try:\n",
    "    assert (\n",
    "        df_XY_imputed[numeric_features].isna().sum().sum() == 0\n",
    "    ), \"NAs remain in numerical\"\n",
    "except:\n",
    "    print(\"NAs remain in numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad761e04",
   "metadata": {},
   "source": [
    "## API Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d620b42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:04.493544Z",
     "start_time": "2022-07-05T14:21:04.382539Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## import api spec\n",
    "\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "\n",
    "with open(\"data-tests/_apispecs.yaml\") as f:\n",
    "    api_specs = yaml.load(f, Loader=Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6570cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:10.317537Z",
     "start_time": "2022-07-05T14:21:04.498549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation completed\n"
     ]
    }
   ],
   "source": [
    "## validate based on api spec\n",
    "\n",
    "from openapi_schema_validator import validate\n",
    "import json\n",
    "\n",
    "schema = api_specs[\"components\"][\"schemas\"][\"Tradelog\"]\n",
    "\n",
    "json_str = df_XY_imputed.to_json(orient=\"records\")\n",
    "json_test = json.loads(json_str)\n",
    "\n",
    "i = 0\n",
    "for row in json_test:\n",
    "    try:\n",
    "        validate(row, schema)\n",
    "    except:\n",
    "        print(f\"failed on {i}th row \")\n",
    "        break\n",
    "    i = i + 1\n",
    "\n",
    "print(\"validation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f92a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:10.688538Z",
     "start_time": "2022-07-05T14:21:10.320536Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save api spec to html\n",
    "\n",
    "import os\n",
    "\n",
    "# feed yaml file to swagger python, then create api.html\n",
    "os.system(\n",
    "    \"python swagger_yaml_to_html.py < data-tests/_apispecs.yaml > templates/api.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6574f30",
   "metadata": {},
   "source": [
    "## Resort & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d722f77c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:10.704539Z",
     "start_time": "2022-07-05T14:21:10.692539Z"
    }
   },
   "outputs": [],
   "source": [
    "df_XY_imputed = df_XY_imputed.reindex(sorted(df_XY_imputed.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b01a7cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:10.875537Z",
     "start_time": "2022-07-05T14:21:10.711540Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## save results\n",
    "\n",
    "df_XY_imputed.to_csv(\"output/e_resultcleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d949fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T14:21:10.906538Z",
     "start_time": "2022-07-05T14:21:10.881550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/e_preprocessor_na.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save imputer\n",
    "\n",
    "dump(preprocessor_na, \"output/e_preprocessor_na.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:percent,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "p1analyzetrades",
   "language": "python",
   "name": "p1analyzetrades"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
