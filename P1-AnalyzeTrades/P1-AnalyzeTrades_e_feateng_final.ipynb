{"cells":[{"cell_type":"markdown","metadata":{},"source":["  ## E: Feature Engineering"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# imports\n","\n","import pandas as pd\n","import numpy as np\n","\n","# for na pipeline\n","import warnings\n","import sklearn\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.base import TransformerMixin # for custom transformers\n","\n","from joblib import dump, load\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# read in data\n","\n","df_XY = pd.read_csv('output/c_resulttradewattr.csv')\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#  get_feature_names function \n","# https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n","def get_feature_names(column_transformer):\n","    \"\"\"Get feature names from all transformers.\n","    Returns\n","    -------\n","    feature_names : list of strings\n","        Names of the features produced by transform.\n","    \"\"\"\n","    # Remove the internal helper function\n","    #check_is_fitted(column_transformer)\n","    \n","    # Turn loopkup into function for better handling with pipeline later\n","    def get_names(trans):\n","        # >> Original get_feature_names() method\n","        if trans == 'drop' or (\n","                hasattr(column, '__len__') and not len(column)):\n","            return []\n","        if trans == 'passthrough':\n","            if hasattr(column_transformer, '_df_columns'):\n","                if ((not isinstance(column, slice))\n","                        and all(isinstance(col, str) for col in column)):\n","                    return column\n","                else:\n","                    return column_transformer._df_columns[column]\n","            else:\n","                indices = np.arange(column_transformer._n_features)\n","                return [i for i in indices[column]]\n","        if not hasattr(trans, 'get_feature_names'):\n","        # >>> Change: Return input column names if no method avaiable\n","            # Turn error into a warning\n","            warnings.warn(\"Transformer %s (type %s) does not \"\n","                                 \"provide get_feature_names. \"\n","                                 \"Will return input column names if available\"\n","                                 % (str(name), type(trans).__name__))\n","            # For transformers without a get_features_names method, use the input\n","            # names to the column transformer\n","            if column is None:\n","                return []\n","            else:\n","                return [f for f in column]\n","\n","        return [f for f in trans.get_feature_names()]\n","    \n","    ### Start of processing\n","    feature_names = []\n","    \n","    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n","    if type(column_transformer) == sklearn.pipeline.Pipeline:\n","        l_transformers = [(name, trans, None) for step, name, trans in column_transformer._iter()]\n","    else:\n","        # For column transformers, follow the original method\n","        l_transformers = column_transformer.transformers_\n","    \n","    \n","    for name, trans, column in l_transformers: \n","        if type(trans) == sklearn.pipeline.Pipeline:\n","            # Recursive call on pipeline\n","            _names = get_feature_names(trans)\n","            # if pipeline has no transformer that returns names\n","            if len(_names)==0:\n","                _names = [f for f in column]\n","            feature_names.extend(_names)\n","        else:\n","            feature_names.extend(get_names(trans))\n","    \n","    return feature_names\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# custom transformers\n","class Numerizer(TransformerMixin):\n","    import pandas as pd\n","    \n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        Y = X.apply(pd.to_numeric, errors='coerce')\n","        return Y\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-20b153452ec6>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n  pd.Series(df_XY.columns).astype(str).str.replace(' ','_', regex=True)\\\n<ipython-input-3-dcc831992e80>:32: UserWarning: Transformer numerizer (type Numerizer) does not provide get_feature_names. Will return input column names if available\n  warnings.warn(\"Transformer %s (type %s) does not \"\n<ipython-input-3-dcc831992e80>:32: UserWarning: Transformer imputer (type SimpleImputer) does not provide get_feature_names. Will return input column names if available\n  warnings.warn(\"Transformer %s (type %s) does not \"\n"]}],"source":["# create na pipeline\n","\n","# update columns headers to clean up\n","df_XY.columns = list(\n","    pd.Series(df_XY.columns).astype(str).str.replace(' ','_', regex=True)\\\n","        .str.upper().str.strip().str.replace('/','_').str.replace('*','_')\n",")\n","\n","# start with numeric, utilizng explore data before\n","numeric_features = df_XY.select_dtypes(include=np.number).columns.tolist()\n","numeric_features = numeric_features + [\n","    '%_TO_STOP',\n","    '%_TO_TARGET',\n","    'GROWTH_0.5TO0.75',\n","    'ROIC_(BW_ROA_ROE)',\n","    'IMPLIED_P_E',\n","    'YEARS_TO_NORMALIZATION',\n","]\n","numeric_features = list(set(numeric_features))\n","\n","numeric_transformer = Pipeline(\n","    steps=[\n","        ('numerizer', Numerizer()),          \n","        ('imputer', SimpleImputer(strategy='constant', fill_value = 0)),\n","    ]\n",")\n","\n","# numerical\n","\n","# categorical_features = ['embarked', 'sex', 'pclass']\n","# categorical_transformer = Pipeline(steps=[\n","#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","preprocessor_na = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features)  \n","    ], \n","    remainder = 'passthrough'\n",")\n","\n","XY_imputed = preprocessor_na.fit_transform(df_XY)\n","\n","columns =get_feature_names(preprocessor_na)\n","\n","df_XY_imputed = pd.DataFrame(XY_imputed,columns=columns)\n","\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# create target \n","\n","df_XY_imputed['PCT_RET_FINAL'] = (\n","    df_XY_imputed['PNL'] / ( df_XY_imputed['OPEN_PRICE'] *  df_XY_imputed['QUANTITY']) \n",")\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# TODO create moving avg\n","\n","\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['QUANTITY', 'AAII_SENT_TOTAL', 'IMPLIED_P_E', 'COMMISSION',\n       'CLOSE_^VIX', '%_TO_STOP', 'UNNAMED:_0_Y', 'AAII_SENT_S&P500WEEKLYHIGH',\n       'AAII_SENT_BULLISH8WEEKMOVAVG', '%_TO_TARGET', 'PRICE',\n       'AAII_SENT_BULLBEARSPREAD', 'ROIC_(BW_ROA_ROE)', 'AAII_SENT_NEUTRAL',\n       'AAII_SENT_BULLISHAVERAGESTDEV', 'UNNAMED:_0', 'UNNAMED:_0.1',\n       'DAYSTOFYEND', 'AAII_SENT_BULLISHAVERAGE+STDEV', 'PNL', 'QTYCHG',\n       'AAII_SENT_BEARISH', 'AAII_SENT_S&P500WEEKLYCLOSE', 'DETAILS',\n       'AAII_SENT_BULLISHAVERAGE', 'UNNAMED:_0_X', 'CLOSE_PRICE',\n       'YEARS_TO_NORMALIZATION', 'AAII_SENT_S&P500WEEKLYLOW', 'OPEN_PRICE',\n       'AAII_SENT_BULLISH', 'CLOSE_^GSPC', 'COMM_TOT', 'GROWTH_0.5TO0.75',\n       'OPEN_DATE', 'CLOSE_DATE', 'SYMBOL', 'OPENACT', 'CLOSEACT', 'DATE',\n       'ACTION', 'TIME', 'UNNAMED:_6', 'UNNAMED:_8', 'CASH_CHG_(PNL)',\n       'COMMENTS', 'PCTRETURN', 'STARTDATE',\n       'COMPANY_NAME_(IN_ALPHABETICAL_ORDER)', 'TICKER', 'STOP',\n       'CURRENT_PRICE', 'AT_PRICE', 'TARGET', 'EPS1', 'EPS2', 'FYEND',\n       'FYEPSNXT', 'LASTUPDATED', 'CATEGORY', 'COMMENTS.1', 'FILENAME',\n       'DATE_', 'AAII_SENT_DATE', 'PCT_RET_FINAL'],\n      dtype='object')\n"]}],"source":["# Final columns\n","\n","print(df_XY_imputed.columns)\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# check no na's left in numerical\n","\n","try: \n","    assert df_XY_imputed[numeric_features].isna().sum().sum() == 0 , 'NAs remain in numerical'\n","except:\n","    print('NAs remain in numerical')\n",""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# save results\n","\n","df_XY_imputed.to_csv('output/e_resultcleaned.csv')\n","\n",""]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['output/e_preprocessor_na.joblib']"]},"metadata":{},"execution_count":11}],"source":["# save imputer\n","\n","dump(preprocessor_na,'output/e_preprocessor_na.joblib')\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}